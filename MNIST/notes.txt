MNIST simulation in C++

4/25/2017
So for now I am going to simulate a recurrent Neural
Network that runs the benchmark MNIST handwritten
number catagorization test. I'm making this git
repository so I am able to work in the lab as well
as from the dorm or the library. The steps I will
take to complete this will be as follows. 
1.) Design solution on paper and review past work
2.) make program

Obviously there will be parts 1.1 and 2.1 but thats
a later problem.

5/8/2017
Beginning to create the NN in C++ initially focusing
on the ability to read the appropreate MNIST data
set and return the information in array structures
that I can process accordingly. Still re-learning
the versatilites of vim and will need to either 
write my own matrix math functions or if I can
leverage MATLAB and its highly developed matrix lib.

Would like to finish the research and the Stanford
CS231n Convolutional Neural Networks online lecture
notes analysis by this Thursday and fully understood
my end goal design by this Friday. Today though I
want to have the read function and finish many notes

5/9/2017
Learned more of the basics yesterday of construction
of my neural net, and I'll look to implement some
cool features as well as some nessacary ones. Really
need to hone down today on how I am going to handle
my matrix algebra. Most likely will use Eigen as it
has very little setup and has lots of support info
online. Today will also try to address how to read
mnist file.

Design update:: 
My original idea of placing all of my code within
one call function may be misguided and I'll try to 
approach the problem from a different point of view.
I will be making two programs. One that creates and
teaches a neural network from random weights and 
trains those weights to to MNIST dataset, then
records those datapoints into a seperate file 
(most likely binary) then run a second program that
constructs a neural network with priviously 
generated weights and test the accuracy of those
weights on the test MNIST dataset, outputting a 
percent error readout.::

5/11/2017
To complete today: finish MNIST dataset reader 
functions to be used in both test and train 
processes. If that gets finished then begin first
layer of train neural net. Finished readings on 
gradient decent and calulating loss functions so
hopefully implentation of that today can happen.
